{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bc95809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "728c09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "file_path = Path(\"archive/movies.csv\")\n",
    "df_movie = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "6741c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split release data and create a monthly column\n",
    "\n",
    "df_movie[\"released\"] = df_movie[\"released\"].str.split(\"\\s+\\(\").str[0]\n",
    "\n",
    "df_movie[\"released\"] = pd.to_datetime(df_movie['released'])\n",
    "\n",
    "df_movie [\"released\"] = df_movie[\"released\"].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "18622ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie['trixbudget']= df_movie['gross'] - 3.0*df_movie['budget']\n",
    "df_movie['success'] = df_movie['trixbudget'].map(lambda x: x>0).astype(int)\n",
    "df_movie_clean = df_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "dc9f6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.6202 - accuracy: 0.6828\n",
      "Epoch 2/11\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.5310 - accuracy: 0.6875\n",
      "Epoch 3/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3526 - accuracy: 0.8865\n",
      "Epoch 4/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.2168 - accuracy: 0.9562\n",
      "Epoch 5/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9734\n",
      "Epoch 6/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9815\n",
      "Epoch 7/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0869 - accuracy: 0.9864\n",
      "Epoch 8/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0693 - accuracy: 0.9895\n",
      "Epoch 9/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9924\n",
      "Epoch 10/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9924\n",
      "Epoch 11/11\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9939\n",
      "43/43 - 0s - loss: 1.2129 - accuracy: 0.5595 - 187ms/epoch - 4ms/step\n",
      "Loss: 1.2128785848617554, Accuracy: 0.5595325231552124\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie_clean.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=8834))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "2a4032c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign values as other for counts under certain values\n",
    "\n",
    "df_movie['director_number'] = df_movie.groupby('director')['score'].transform('sum')/df_movie.groupby('director')['score'].transform('count')\n",
    "df_movie['writer_number'] = df_movie.groupby('writer')['score'].transform('sum')/df_movie.groupby('writer')['score'].transform('count')\n",
    "df_movie['star_number'] = df_movie.groupby('star')['score'].transform('sum')/df_movie.groupby('star')['score'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "bbddcd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.6143 - accuracy: 0.6864\n",
      "Epoch 2/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.7724\n",
      "Epoch 3/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.2435 - accuracy: 0.9483\n",
      "Epoch 4/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.9771\n",
      "Epoch 5/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0944 - accuracy: 0.9839\n",
      "Epoch 6/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0700 - accuracy: 0.9895\n",
      "Epoch 7/11\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.0548 - accuracy: 0.9922\n",
      "Epoch 8/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9934\n",
      "Epoch 9/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9949\n",
      "Epoch 10/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9956\n",
      "Epoch 11/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9959\n",
      "43/43 - 0s - loss: 1.2200 - accuracy: 0.6019 - 184ms/epoch - 4ms/step\n",
      "Loss: 1.2200157642364502, Accuracy: 0.6018992066383362\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=8833))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "dfd1e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for character count of movie title\n",
    "\n",
    "df_movie_clean['title_char'] = df_movie_clean['name'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "82c8f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.5736\n",
      "Epoch 2/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5948 - accuracy: 0.6864\n",
      "Epoch 3/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.5133 - accuracy: 0.6879\n",
      "Epoch 4/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.3947 - accuracy: 0.8662\n",
      "Epoch 5/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.9549\n",
      "Epoch 6/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9759\n",
      "Epoch 7/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9854\n",
      "Epoch 8/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0784 - accuracy: 0.9898\n",
      "Epoch 9/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9934\n",
      "Epoch 10/11\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9937\n",
      "Epoch 11/11\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9949\n",
      "43/43 - 0s - loss: 1.0051 - accuracy: 0.6435 - 192ms/epoch - 4ms/step\n",
      "Loss: 1.0051065683364868, Accuracy: 0.6435354351997375\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=8834))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "8b5e02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for sequel indicator and assign value of 1 or 0\n",
    "\n",
    "df_movie['sequel'] = df_movie['name'].str.extract('(^\\d*)')\n",
    "\n",
    "df_movie['sequels']=df_movie['sequel'].isin([\"\"]).astype(int)\n",
    "\n",
    "df_movie = df_movie.drop(columns=['sequel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "30eae8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "129/129 [==============================] - 2s 6ms/step - loss: 0.7412 - accuracy: 0.4332\n",
      "Epoch 2/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.6011 - accuracy: 0.7025\n",
      "Epoch 3/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.5301 - accuracy: 0.7488\n",
      "Epoch 4/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.4343 - accuracy: 0.8694\n",
      "Epoch 5/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.3188 - accuracy: 0.9296\n",
      "Epoch 6/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.2151 - accuracy: 0.9566\n",
      "Epoch 7/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1473 - accuracy: 0.9734\n",
      "Epoch 8/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.1062 - accuracy: 0.9815\n",
      "Epoch 9/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.0793 - accuracy: 0.9866\n",
      "Epoch 10/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.0612 - accuracy: 0.9907\n",
      "Epoch 11/11\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 0.0493 - accuracy: 0.9927\n",
      "43/43 - 0s - loss: 0.9650 - accuracy: 0.6574 - 223ms/epoch - 5ms/step\n",
      "Loss: 0.9649800062179565, Accuracy: 0.6574141979217529\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie_clean.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=8876))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "80e0560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added averaged score values for director, writer and star\n",
    "\n",
    "director_other = df_movie_clean['director'].value_counts() < 15\n",
    "df_movie_clean.loc[df_movie_clean['director'].isin(director_other.index[director_other]), 'director'] = 'others'\n",
    "\n",
    "writer_other = df_movie_clean['writer'].value_counts() < 10\n",
    "df_movie_clean.loc[df_movie_clean['writer'].isin(writer_other.index[writer_other]), 'writer'] = 'others'\n",
    "\n",
    "star_other = df_movie_clean['star'].value_counts() < 11\n",
    "df_movie_clean.loc[df_movie_clean['star'].isin(star_other.index[star_other]), 'star'] = 'others'\n",
    "\n",
    "country_other = df_movie_clean['country'].value_counts() < 25\n",
    "df_movie_clean.loc[df_movie_clean['country'].isin(country_other.index[country_other]), 'country'] = 'others'\n",
    "\n",
    "company_other = df_movie_clean['company'].value_counts() < 100\n",
    "df_movie_clean.loc[df_movie_clean['company'].isin(company_other.index[company_other]), 'company'] = 'others'\n",
    "\n",
    "rating_other = df_movie_clean['rating'].value_counts() < 100\n",
    "df_movie_clean.loc[df_movie_clean['rating'].isin(rating_other.index[rating_other]), 'rating'] = 'others'\n",
    "\n",
    "genre_other = df_movie_clean['genre'].value_counts() < 20\n",
    "df_movie_clean.loc[df_movie_clean['genre'].isin(genre_other.index[genre_other]), 'rating'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "0c66dd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "129/129 [==============================] - 1s 2ms/step - loss: 0.6493 - accuracy: 0.6305\n",
      "Epoch 2/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6828\n",
      "Epoch 3/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6828\n",
      "Epoch 4/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.6962\n",
      "Epoch 5/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7138\n",
      "Epoch 6/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7320\n",
      "Epoch 7/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7418\n",
      "Epoch 8/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7454\n",
      "Epoch 9/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7435\n",
      "Epoch 10/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7476\n",
      "Epoch 11/11\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7498\n",
      "43/43 - 0s - loss: 0.6103 - accuracy: 0.6991 - 181ms/epoch - 4ms/step\n",
      "Loss: 0.6103084087371826, Accuracy: 0.6990504264831543\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie_clean.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=302))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "4adb71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_clean = df_movie_clean[df_movie_clean.budget > 15000000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "3b4f15ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 0.6073 - accuracy: 0.7012\n",
      "Epoch 2/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7012\n",
      "Epoch 3/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7012\n",
      "Epoch 4/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7080\n",
      "Epoch 5/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7309\n",
      "Epoch 6/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7457\n",
      "Epoch 7/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7609\n",
      "Epoch 8/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7637\n",
      "Epoch 9/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7665\n",
      "Epoch 10/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7737\n",
      "Epoch 11/11\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7709\n",
      "27/27 - 0s - loss: 0.5834 - accuracy: 0.7203 - 195ms/epoch - 7ms/step\n",
      "Loss: 0.583396852016449, Accuracy: 0.720288097858429\n"
     ]
    }
   ],
   "source": [
    "df_movie_clean = df_movie_clean.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=287))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "0862ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_clean = df_movie_clean[df_movie_clean.year > 1985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "b78a49ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.6934\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6934\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6934\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.6979\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7162\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7344\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7419\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7515\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7581\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7622\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7647\n",
      "26/26 - 0s - loss: 0.5591 - accuracy: 0.7276 - 180ms/epoch - 7ms/step\n",
      "Loss: 0.559092104434967, Accuracy: 0.7276119589805603\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie_clean.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "7a625d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpi adjustments:\n",
    "df_movie_clean['budget'] = df_movie_clean['budget']/df_movie_clean['cpi']\n",
    "df_movie_clean['ticket'] = df_movie_clean['ticket']/df_movie_clean['cpi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "cba76a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 1s 2ms/step - loss: 0.6583 - accuracy: 0.6195\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6938\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6950\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7012\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7174\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7295\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7427\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7531\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7573\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7651\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7705\n",
      "26/26 - 0s - loss: 0.5477 - accuracy: 0.7313 - 156ms/epoch - 6ms/step\n",
      "Loss: 0.5477478504180908, Accuracy: 0.7313432693481445\n"
     ]
    }
   ],
   "source": [
    "#df_movie_clean = df_movie_clean.drop(columns=['name', 'trixbudget', 'gross', 'score', 'votes'])\n",
    "\n",
    "#df_movie_clean = df_movie_clean.dropna()\n",
    "\n",
    "df_movie_dummies = pd.get_dummies(df_movie_clean)\n",
    "\n",
    "y = df_movie_dummies[\"success\"]\n",
    "\n",
    "X = df_movie_dummies.drop(columns=['success'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "8a9b314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 1s 2ms/step - loss: 3.6571 - accuracy: 0.5278\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.9857 - accuracy: 0.5755\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.7307 - accuracy: 0.6033\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.5714 - accuracy: 0.6174\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.4042 - accuracy: 0.6315\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.2612 - accuracy: 0.6485\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.1697 - accuracy: 0.6635\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.1050 - accuracy: 0.6768\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0767 - accuracy: 0.6817\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0503 - accuracy: 0.6880\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 2.0322 - accuracy: 0.6905\n",
      "26/26 - 0s - loss: 2.4843 - accuracy: 0.6206 - 180ms/epoch - 7ms/step\n",
      "Loss: 2.4842870235443115, Accuracy: 0.6206467747688293\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"relu\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e51d4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 1s 2ms/step - loss: 0.7901 - accuracy: 0.6664\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.7062\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7241\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7332\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7394\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7440\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7448\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7564\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7560\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7606\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7656\n",
      "26/26 - 0s - loss: 0.6576 - accuracy: 0.7326 - 178ms/epoch - 7ms/step\n",
      "Loss: 0.6576422452926636, Accuracy: 0.7325870394706726\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "3e438499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 1s 2ms/step - loss: 0.7047 - accuracy: 0.6934\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.6934\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.6967\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7000\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7050\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7220\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7378\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7444\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7531\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7573\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7564\n",
      "26/26 - 0s - loss: 0.7134 - accuracy: 0.7239 - 443ms/epoch - 17ms/step\n",
      "Loss: 0.7134127020835876, Accuracy: 0.7238805890083313\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "de19be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 2s 2ms/step - loss: 0.6767 - accuracy: 0.5880\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6975\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7021\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7253\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7261\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7257\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7340\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7357\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7415\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7432\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7490\n",
      "26/26 - 0s - loss: 0.6856 - accuracy: 0.7413 - 175ms/epoch - 7ms/step\n",
      "Loss: 0.6856076121330261, Accuracy: 0.7412935495376587\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "9de3455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "76/76 [==============================] - 2s 2ms/step - loss: 0.6923 - accuracy: 0.5216\n",
      "Epoch 2/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6942\n",
      "Epoch 3/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6934\n",
      "Epoch 4/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6979\n",
      "Epoch 5/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7095\n",
      "Epoch 6/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7361\n",
      "Epoch 7/11\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7477\n",
      "Epoch 8/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7548\n",
      "Epoch 9/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7643\n",
      "Epoch 10/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7664\n",
      "Epoch 11/11\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7739\n",
      "26/26 - 0s - loss: 0.5516 - accuracy: 0.7276 - 180ms/epoch - 7ms/step\n",
      "Loss: 0.5515791773796082, Accuracy: 0.7276119589805603\n"
     ]
    }
   ],
   "source": [
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=20, activation=\"sigmoid\", input_dim=285))\n",
    "nn_model.add(tf.keras.layers.Dense(units=8, activation=\"sigmoid\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=11)\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3047d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
